{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2549419,"sourceType":"datasetVersion","datasetId":1546318}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style='background:#418E32; border:1; color:#F0FFFF; text-align:center; font-size:32px;  padding:6px;'><left>Customer Segmentation with Clustering Model</left></h1>","metadata":{}},{"cell_type":"markdown","source":"**Created By**: Wuttipat S. <br>\n**Created Date**: 2024-05-19 <br>\n**Status**: <span style=\"color:green\">Completed</span>","metadata":{}},{"cell_type":"markdown","source":" <h3 style='background:green; color:#F0FFFF; text-align:center'><left>If you found my notebook helpful or informative, please consider upvoting it to show your support üëç</left></h3>","metadata":{}},{"cell_type":"markdown","source":"# Index\n---\nCustomer Personality Analysis is an in-depth examination of a business's target consumers. It enables a company to gain a deeper understanding of its customers, facilitating the tailoring of products to meet the distinct needs, behaviors, and concerns of various customer groups.\n\nThis analysis allows a business to fine-tune its products for specific customer segments. For instance, rather than marketing a new product to every customer in their database, a company can identify which segment is most likely to purchase the product and focus its marketing efforts solely on that group.","metadata":{}},{"cell_type":"markdown","source":"# Dataset Content\n---\n\n\n### People\n\n- ID: Customer's unique identifier\n- Year_Birth: Customer's birth year\n- Education: Customer's education level\n- Marital_Status: Customer's marital status\n- Income: Customer's yearly household income\n- Kidhome: Number of children in customer's household\n- Teenhome: Number of teenagers in customer's household\n- Dt_Customer: Date of customer's enrollment with the company\n- Recency: Number of days since customer's last purchase\n- Complain: 1 if the customer complained in the last 2 years, 0 otherwise\n\n### Products\n\n- MntWines: Amount spent on wine in last 2 years\n- MntFruits: Amount spent on fruits in last 2 years\n- MntMeatProducts: Amount spent on meat in last 2 years\n- MntFishProducts: Amount spent on fish in last 2 years\n- MntSweetProducts: Amount spent on sweets in last 2 years\n- MntGoldProds: Amount spent on gold in last 2 years\n\n### Promotion\n\n- NumDealsPurchases: Number of purchases made with a discount\n- AcceptedCmp1: 1 if customer accepted 1st campaign offer, 0 otherwise\n- AcceptedCmp2: 1 if customer accepted 2nd campaign offer, 0 otherwise\n- AcceptedCmp3: 1 if customer accepted 3rd campaign offer, 0 otherwise\n- AcceptedCmp4: 1 if customer accepted 4th campaign offer, 0 otherwise\n- AcceptedCmp5: 1 if customer accepted 5th campaign offer, 0 otherwise\n- Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n\n### Place\n\n- NumWebPurchases: Number of purchases made through the company‚Äôs website\n- NumCatalogPurchases: Number of purchases made using a catalogue\n- NumStorePurchases: Number of purchases made directly in stores\n- NumWebVisitsMonth: Number of visits to company‚Äôs website in the last month","metadata":{}},{"cell_type":"code","source":"import warnings\n\n# Ignore all warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:54.153233Z","iopub.execute_input":"2024-05-19T14:51:54.153634Z","iopub.status.idle":"2024-05-19T14:51:54.185830Z","shell.execute_reply.started":"2024-05-19T14:51:54.153601Z","shell.execute_reply":"2024-05-19T14:51:54.184936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nVertify what environment are running\n'''\nimport os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n\nif iskaggle:\n    path='/kaggle/input/customer-personality-analysis' \nelse:\n    path=\"{}\".format(os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:54.187214Z","iopub.execute_input":"2024-05-19T14:51:54.187835Z","iopub.status.idle":"2024-05-19T14:51:54.193495Z","shell.execute_reply.started":"2024-05-19T14:51:54.187805Z","shell.execute_reply":"2024-05-19T14:51:54.192370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style='background:#95E885; border:1; color:#F0FFFF; text-align:left; font-size:24px;  padding:6px;'><left>Import Libraries</left></h1>\n---","metadata":{"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.max_columns', None)\n\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:54.194556Z","iopub.execute_input":"2024-05-19T14:51:54.195216Z","iopub.status.idle":"2024-05-19T14:51:57.121896Z","shell.execute_reply.started":"2024-05-19T14:51:54.195187Z","shell.execute_reply":"2024-05-19T14:51:57.120794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Dataset <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>","metadata":{"tags":[]}},{"cell_type":"code","source":"# Import dataset\ndata = pd.read_csv(f\"{path}/marketing_campaign.csv\", sep='\\t')\ndisplay(data.info())\n\ndisplay(data.describe())\ndisplay(data.head())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-19T14:51:57.123766Z","iopub.execute_input":"2024-05-19T14:51:57.124213Z","iopub.status.idle":"2024-05-19T14:51:57.264462Z","shell.execute_reply.started":"2024-05-19T14:51:57.124185Z","shell.execute_reply":"2024-05-19T14:51:57.263286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The data contains 29 variables and 2240 observations.","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>\n---\n\n- Drop unuse columns\n- Validate columns datatype\n- Remove missing values\n- Remove outliers","metadata":{}},{"cell_type":"markdown","source":"### Drop **unuse** columns\n\n- **ID**: Remove because it's a unique identifier per customer, which doesn't contribute to predictive modeling and only serves to identify records.\n\n- **Z_CostContact and Z_Revenue**: Remove because they have constant values across all data, providing no variability or useful information for analysis.\n","metadata":{}},{"cell_type":"code","source":"# Drop unnecessary columns \ndata1 = data.drop(['ID', 'Z_CostContact', 'Z_Revenue'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:57.265829Z","iopub.execute_input":"2024-05-19T14:51:57.266500Z","iopub.status.idle":"2024-05-19T14:51:57.274724Z","shell.execute_reply.started":"2024-05-19T14:51:57.266461Z","shell.execute_reply":"2024-05-19T14:51:57.273658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validate columns **datatype**\n\n\n- This table provides a structured overview to ensure that each feature is treated with the correct data type, facilitating more effective data handling and analysis.\n\n| Feature Name           | Correct Data Type |\n|------------------------|-------------------|\n| Year_Birth             | int               |\n| Education              | category          |\n| Marital_Status         | category          |\n| Income                 | float             |\n| Kidhome                | int               |\n| Teenhome               | int               |\n| Dt_Customer            | datetime          |\n| Recency                | int               |\n| MntWines               | int               |\n| MntFruits              | int               |\n| MntMeatProducts        | int               |\n| MntFishProducts        | int               |\n| MntSweetProducts       | int               |\n| MntGoldProds           | int               |\n| NumDealsPurchases      | int               |\n| NumWebPurchases        | int               |\n| NumCatalogPurchases    | int               |\n| NumStorePurchases      | int               |\n| NumWebVisitsMonth      | int               |\n| AcceptedCmp3           | bool              |\n| AcceptedCmp4           | bool              |\n| AcceptedCmp5           | bool              |\n| AcceptedCmp1           | bool              |\n| AcceptedCmp2           | bool              |\n| Complain               | bool              |\n| Response               | bool              |\n","metadata":{}},{"cell_type":"code","source":"'''\nValidate Columns Datatype\n'''\n\n# List of categorical columns\ncategorical_cols = ['Education', 'Marital_Status']\n\n# List of boolean columns\nboolean_cols = ['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3',\n                'AcceptedCmp4','AcceptedCmp5', 'Complain', 'Response']\n\n# List of numerical columns\nnumerical_cols = ['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', \n                  'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', \n                  'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', \n                  'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', \n                  'NumWebVisitsMonth']\n\n# Convert categorical columns to 'category' datatype\nfor col in categorical_cols:\n    data1[col] = data1[col].astype('category')\n\n# Convert boolean columns to 'boolean' datatype\nfor col in boolean_cols:\n    data1[col] = data1[col].astype('boolean')\n\n# Convert 'Dt_Customer' to datetime\ndata1['Dt_Customer'] = pd.to_datetime(data1['Dt_Customer'], format='%d-%m-%Y')\n\n\n\n# Compare datatypes of the original and new DataFrames\ncompare_dtypes = pd.DataFrame({\n    'Original DataType': data.dtypes,\n    'New DataType': data1.dtypes\n})\n\ncompare_dtypes","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:57.276165Z","iopub.execute_input":"2024-05-19T14:51:57.276938Z","iopub.status.idle":"2024-05-19T14:51:57.311383Z","shell.execute_reply.started":"2024-05-19T14:51:57.276909Z","shell.execute_reply":"2024-05-19T14:51:57.310369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove **missing values**","metadata":{"tags":[]}},{"cell_type":"code","source":"# Display missing values in a dataset\nsns.heatmap(data1.isna())\nplt.title('Missing values in dataset')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:57.312844Z","iopub.execute_input":"2024-05-19T14:51:57.313129Z","iopub.status.idle":"2024-05-19T14:51:57.977644Z","shell.execute_reply.started":"2024-05-19T14:51:57.313105Z","shell.execute_reply":"2024-05-19T14:51:57.976500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The 'Income' feature contains missing values that will be removed.","metadata":{}},{"cell_type":"code","source":"# Removeing missing values\ndata2 = data1.dropna(axis=0, how='any')\n\n# Creating dataframe comapring before and after process\ncompare_missing_values = pd.DataFrame({'Original': data1.isna().sum(),\n                                       'After': data2.isna().sum()})\n\nprint(\"Number of missing values: \")\ndisplay(compare_missing_values)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:57.981220Z","iopub.execute_input":"2024-05-19T14:51:57.984541Z","iopub.status.idle":"2024-05-19T14:51:58.004295Z","shell.execute_reply.started":"2024-05-19T14:51:57.984503Z","shell.execute_reply":"2024-05-19T14:51:58.003464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The 24 missing value in **'Income'** variable have been removed.","metadata":{}},{"cell_type":"markdown","source":"### Remove **outliers**\n\n    - I apply standardize to all numerical columns before plot, so we can detect an outlier easier.","metadata":{}},{"cell_type":"code","source":"# Normalizing the numerical columns\nnormalized_data = (data2[numerical_cols] - data2[numerical_cols].mean()) / data2[numerical_cols].std()\n\n# Identify the most left outlier in 'Year_Birth'\nyear_birth_min_outlier = normalized_data['Year_Birth'].idxmin()\n\n# Identify the most right outlier in 'Income'\nincome_max_outlier = normalized_data['Income'].idxmax()\n\n# Plotting the boxplot\nplt.figure(figsize=(15, 10))\nsns_boxplot = sns.boxplot(data=normalized_data, orient='h')\nplt.title(\"Normalized Boxplot for Numerical Columns\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Normalized Values\")\n\n# Annotating the most left outlier for 'Year_Birth'\nplt.annotate('Outlier',\n             xy=(normalized_data['Year_Birth'][year_birth_min_outlier], numerical_cols.index('Year_Birth')),\n             xytext=(normalized_data['Year_Birth'][year_birth_min_outlier] + 0, numerical_cols.index('Year_Birth') + 2),\n             arrowprops=dict(facecolor='red', shrink=0.1),\n             fontsize=14, ha='center')\n\n# Annotating the most right outlier for 'Income'\nplt.annotate('Outlier',\n             xy=(normalized_data['Income'][income_max_outlier], numerical_cols.index('Income')),\n             xytext=(normalized_data['Income'][income_max_outlier] + 0, numerical_cols.index('Income') + 2),\n             arrowprops=dict(facecolor='red', shrink=0.1),\n             fontsize=14, ha='center')\n\n# Turning off the x-axis ticks\nplt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:58.005716Z","iopub.execute_input":"2024-05-19T14:51:58.006017Z","iopub.status.idle":"2024-05-19T14:51:58.652517Z","shell.execute_reply.started":"2024-05-19T14:51:58.005993Z","shell.execute_reply":"2024-05-19T14:51:58.651470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> As notice that there are two group of extreme outlier in 'Year_Birth' and 'Income'. Let focus only two variables.","metadata":{}},{"cell_type":"code","source":"# Setting up the subplots\nfig, axs = plt.subplots(nrows=2, ncols=1, figsize=(8, 4))\n\n# Plotting 'Year_Birth' on the first subplot\nsns.boxplot(data=data2['Year_Birth'], orient='h', ax=axs[0])\naxs[0].set_title('Boxplot of Year_Birth')\n\n# Plotting 'Income' on the second subplot\nsns.boxplot(data=data2['Income'], orient='h', ax=axs[1])\naxs[1].set_title('Boxplot of Income')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:58.653867Z","iopub.execute_input":"2024-05-19T14:51:58.654185Z","iopub.status.idle":"2024-05-19T14:51:58.996607Z","shell.execute_reply.started":"2024-05-19T14:51:58.654159Z","shell.execute_reply":"2024-05-19T14:51:58.995480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">- The boxplot reveals outliers with birth years before 1900, indicating these are either significantly older individuals or deceased.\n>- Similarly, the income data shows one extremely individual outlier with an income around $600,000. This could indicate a data entry error, an anomaly, or a genuinely high-income individual.\n>- These outliers will be remove.","metadata":{}},{"cell_type":"code","source":"# Removing outliers\nyear_outlier = (data2['Year_Birth'] > 1920)\nincome_outlier = (data2['Income'] < 200000)\n\ndata3 = data2[year_outlier & income_outlier]\n\nprint(data2[['Year_Birth','Income']].describe())\nprint(\"\\n===== After removing outliers =====\\n\")\nprint(data3[['Year_Birth','Income']].describe())","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:58.997888Z","iopub.execute_input":"2024-05-19T14:51:58.998202Z","iopub.status.idle":"2024-05-19T14:51:59.021439Z","shell.execute_reply.started":"2024-05-19T14:51:58.998175Z","shell.execute_reply":"2024-05-19T14:51:59.020441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The minimum values in 'Year of Birth' and the maximum values in 'Income' have been removed as outliers.","metadata":{}},{"cell_type":"markdown","source":"#### Display data before and after outlier removing","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\n\n# Original Data Plot\nplt.subplot(2, 1, 1)\nsns.boxplot(data=normalized_data, orient='h')\nplt.title(\"Original Data\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Normalized Values\")\nplt.xlabel(\"\")\nplt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)  # Turn off x-axis ticks\n\n\n# Normalizing the filtered data\nnormalized_data_filtered = (data3[numerical_cols] - data3[numerical_cols].mean()) / data3[numerical_cols].std()\n\n\n# Filtered Data Plot\nplt.subplot(2, 1, 2, sharex=plt.gca())\nsns.boxplot(data=normalized_data_filtered, orient='h')\nplt.title(\"Data After Removing Outliers\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Normalized Values\")\nplt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)  # Turn off x-axis ticks\n\n\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:51:59.022618Z","iopub.execute_input":"2024-05-19T14:51:59.022909Z","iopub.status.idle":"2024-05-19T14:52:00.103437Z","shell.execute_reply.started":"2024-05-19T14:51:59.022885Z","shell.execute_reply":"2024-05-19T14:52:00.102342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Display data before and after outlier removing","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\n\n# Original Data Plot\nplt.subplot(2, 1, 1)\nsns.boxplot(data=normalized_data, orient='h')\nplt.title(\"Original Data\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Normalized Values\")\nplt.xlabel(\"\")\nplt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)  # Turn off x-axis ticks\n\n\n# Filtered Data Plot\nplt.subplot(2, 1, 2, sharex=plt.gca())\nsns.boxplot(data=normalized_data_filtered, orient='h')\nplt.title(\"Data After Removing Outliers\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Normalized Values\")\nplt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)  # Turn off x-axis ticks\n\n\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:00.104700Z","iopub.execute_input":"2024-05-19T14:52:00.105058Z","iopub.status.idle":"2024-05-19T14:52:01.117980Z","shell.execute_reply.started":"2024-05-19T14:52:00.105029Z","shell.execute_reply":"2024-05-19T14:52:01.116902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Now the data is cleaned and ready to perform a futher analysis tasks. Next step is **'Feature Engineering'**.\n---","metadata":{}},{"cell_type":"markdown","source":"\n# Feature Engineering <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>\n---\n\nCreate new features to improve analysis aspect and model efficiency.\n- Age: Age of customer.\n- Year_Membership: Preriod of membership.\n- Adult_home: Number of adults living in a house.\n- Family_Size: Total number of people live in a house.\n- Income_Segment: Income segments based on qauntiles.\n- Total_Spend: Total spending based on sum of amount spending on each product.","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"data4 = data3.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.119655Z","iopub.execute_input":"2024-05-19T14:52:01.120080Z","iopub.status.idle":"2024-05-19T14:52:01.126439Z","shell.execute_reply.started":"2024-05-19T14:52:01.120043Z","shell.execute_reply":"2024-05-19T14:52:01.125228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Age I setting age as time that the dataset was public (2021)\ndata4['Age'] = 2021 - data4['Year_Birth']\n\ndata4[['Year_Birth', 'Age']].head()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.127506Z","iopub.execute_input":"2024-05-19T14:52:01.127813Z","iopub.status.idle":"2024-05-19T14:52:01.148923Z","shell.execute_reply.started":"2024-05-19T14:52:01.127788Z","shell.execute_reply":"2024-05-19T14:52:01.147632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Year_Membership\ndata4['Year_Membership'] = 2021 - data4['Dt_Customer'].dt.year\ndata4[['Dt_Customer', 'Year_Membership']].head()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.150613Z","iopub.execute_input":"2024-05-19T14:52:01.150995Z","iopub.status.idle":"2024-05-19T14:52:01.165220Z","shell.execute_reply.started":"2024-05-19T14:52:01.150966Z","shell.execute_reply":"2024-05-19T14:52:01.164098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adult_home\nmapping = {\n    'Single': 1,\n    'Together': 2,\n    'Married': 2,\n    'Divorced': 1,\n    'Widow': 1,\n    'Alone': 1,\n    'Absurd': 1,\n    'YOLO': 1}\ndata4['Adulthome'] = data4['Marital_Status'].map(mapping)\n\ndata4[['Marital_Status', 'Adulthome']].head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.166455Z","iopub.execute_input":"2024-05-19T14:52:01.166814Z","iopub.status.idle":"2024-05-19T14:52:01.186558Z","shell.execute_reply.started":"2024-05-19T14:52:01.166788Z","shell.execute_reply":"2024-05-19T14:52:01.185407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Family_Size\ndata4['Family_Size'] = data4[['Kidhome', 'Teenhome', 'Adulthome']].sum(axis=1)\ndata4[['Kidhome', 'Teenhome', 'Adulthome', 'Family_Size']].head()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.188309Z","iopub.execute_input":"2024-05-19T14:52:01.188641Z","iopub.status.idle":"2024-05-19T14:52:01.203877Z","shell.execute_reply.started":"2024-05-19T14:52:01.188614Z","shell.execute_reply":"2024-05-19T14:52:01.202639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Income_Segment\ndata4['Income_Segment'] = pd.qcut(data4['Income'], 4, labels=['Low', 'Mid-Low', 'Mid-High', 'High'])\n\nprint(data4['Income'].describe()) #reference\ndata4[['Income', 'Income_Segment']].head()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.205233Z","iopub.execute_input":"2024-05-19T14:52:01.206247Z","iopub.status.idle":"2024-05-19T14:52:01.227288Z","shell.execute_reply.started":"2024-05-19T14:52:01.206208Z","shell.execute_reply":"2024-05-19T14:52:01.226250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data4","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.233342Z","iopub.execute_input":"2024-05-19T14:52:01.233738Z","iopub.status.idle":"2024-05-19T14:52:01.265436Z","shell.execute_reply.started":"2024-05-19T14:52:01.233709Z","shell.execute_reply":"2024-05-19T14:52:01.264185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">The 'Income_Segment' is defined by ranges between the quartiles of the 'Income' column as follows:\n>\n> - 0 to 35,233 = 'Low'\n> - 35,233 to 51,371 = 'Mid-Low'\n> - 51,372 to 68,487 = 'Mid-High'\n> - 68,488 and above = 'High'","metadata":{}},{"cell_type":"code","source":"# Total_Spend\ndata4['Total_Spend'] = data4[['MntWines', 'MntFruits', 'MntMeatProducts',\n                              'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']].sum(axis=1)\ndata4[['MntWines', 'MntFruits', 'MntMeatProducts','MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'Total_Spend']].head()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.266837Z","iopub.execute_input":"2024-05-19T14:52:01.267280Z","iopub.status.idle":"2024-05-19T14:52:01.283685Z","shell.execute_reply.started":"2024-05-19T14:52:01.267246Z","shell.execute_reply":"2024-05-19T14:52:01.282563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset after feature engineering\ndata4.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.285481Z","iopub.execute_input":"2024-05-19T14:52:01.285933Z","iopub.status.idle":"2024-05-19T14:52:01.313122Z","shell.execute_reply.started":"2024-05-19T14:52:01.285896Z","shell.execute_reply":"2024-05-19T14:52:01.311507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Our dataset are ready to analyse. Let start **'Exploratory Data Analysis'** process.","metadata":{}},{"cell_type":"markdown","source":"\n# After Cleaning Summary <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"print(data4.info())\ndisplay(data4.describe())","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.315399Z","iopub.execute_input":"2024-05-19T14:52:01.315762Z","iopub.status.idle":"2024-05-19T14:52:01.395308Z","shell.execute_reply.started":"2024-05-19T14:52:01.315735Z","shell.execute_reply":"2024-05-19T14:52:01.394288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> \n> 1. **Age**: Born around 1940-1996, making them approximately 25-81 years old as of the current year (assume it 2021).\n> 2. **Income**: Has an average annual income of around 51,000 - 52,000.\n> \n> 3. **Family Composition**: Likely to have a small family, with a mean of 0.44 kids and 0.51 teenagers at home. This suggests that they might have one child or teenager living with them, or possibly a mix of both. The average family size, including adults and children, is around 2.6.\n> \n> 4. **Purchasing Habits**: Tends to spend more on wines, with a mean expenditure of around 305 in this category. Also spends on meats, fruits, fish, sweet products, and gold, but to a lesser extent.\n> \n> 5. **Shopping Behavior**: Makes an average of 2.32 deals purchases, 4.09 web purchases, 2.67 catalog purchases, and 5.81 store purchases. Visits the web (presumably the store's website or related online platforms) around 5.32 times a month.\n> \n> 6. **Engagement with Marketing Campaigns**: Generally has low engagement with marketing campaigns, as indicated by the low mean values for accepted campaigns.\n> \n> 7. **Membership Duration**: The majority of customers have been members of the service or loyalty program for approximately 7-8 years, demonstrating sustained loyalty and engagement with the brand. It is unusual that there are no newer members, suggesting that the company may not have accepted new registrations for the past 7 years.\n> \n> 8. **Complaints**: Unlikely to have made complaints, as suggested by the low mean value in the 'Complain' category.\n> <br>\n>\n> Our dataset are ready to analyse. Let start **'Exploratory Data Analysis'** process.","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>\n---\n\n1. **Distribution Analysis**: Analyze the distribution of key numerical variables.\n1. **Categorical Analysis**: Understand the frequency of each category.\n1. **Proportion Analysis**: Understand which family sizes and eduacation level are more prevalent in each income segment.\n1. **Campaign Responses**: Look at how customers responded to different campaigns.\n1. **Purchasing Behavior**: Explore across different channels.\n1. **Impact of Website**: Examime how website impact customer behavious.\n1. **Impact of 'Family Size'**: Explore how family size affects pruchasing, product preferences.\n1. **Correlation Analysis**: Discover the relationship between different viriables.\n1. **Analyzing Variables Across Segments**: Review how variuos varibles such as purchasing patterns differ across distinct customer segments.","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"### 1. Distribution Analysis","metadata":{}},{"cell_type":"code","source":"# List of key numerical columns to visualize\nnumerical_columns = ['Recency', 'MntWines', 'MntFruits',\n       'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'Age',\n       'Year_Membership', 'Family_Size', 'Total_Spend']\n\n# Setting up the figure for multiple subplots\nplt.figure(figsize=(15, 10))\n\n# Plotting histograms for each numerical column\nfor i, col in enumerate(numerical_columns, 1):\n    plt.subplot(4, 4, i)  # Adjust the grid dimensions as needed\n    sns.histplot(data4[col],bins='auto', kde=True)\n    plt.title(col)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:01.396632Z","iopub.execute_input":"2024-05-19T14:52:01.397090Z","iopub.status.idle":"2024-05-19T14:52:06.275878Z","shell.execute_reply.started":"2024-05-19T14:52:01.397063Z","shell.execute_reply":"2024-05-19T14:52:06.274733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The plots shows a series of histograms, each depicting the distribution of a different variable.\n> \n> 1. **Recency**: The distribution appears fairly uniform, suggesting that customers have made purchases throughout the recent period sampled without significant time gaps.\n> \n> 2. **MntWines**: Shows a right-skewed distribution with a peak at lower spending amounts, indicating that most customers spend less on wines, but there is a long tail of customers who spend more.\n> \n> 3. **MntFruits, MntFishProducts, MntSweetProducts, MntGoldProds**: These are all right-skewed distributions, indicating that most customers spend smaller amounts on these product categories, with fewer customers spending more.\n> \n> 4. **MntMeatProducts**: Also right-skewed, with a higher peak, suggesting that while there's a concentration of customers spending less, there's also a substantial number of customers spending a lot on meat products.\n> \n> 5. **NumWebPurchases**: The plot shows that a few customers have made 2-5 purchases on the web, with a portion that has never tried purchasing via the website.\n>\n> 6. **NumCatalogPurchases** The plot shows a right-skewed distribution, indicating that the majority of customers have never tried catalog purchasing. \n>\n> 7. **NumStorePurchases** Although the plot shows signs of a right-skewed distribution, store purchases have a slightly gentler slope compared to other purchasing channels. Additionally, there are nearly no customers who have never made a store purchase.\n> \n> 6. **NumDealsPurchases**: This histogram displays a high peak at the lower end, indicating that most customers purchase at least one discounted deal. There is a rapid decrease in the number of customers as the count of deal purchases increases.\n> \n> 7. **NumWebVisitsMonth**: The distribution has a hign peak between 5-10 times, suggesting that most customers visit the company's website a few times per month.\n> \n> 8. **Age**: The distribution of age looks approximately bell-shaped, centered around late middle age, implying a diverse customer base but with a concentration in late-middle-aged customers.\n> \n> 9. **Year_Membership**: The data suggests that a significant number of customers have been members for approximately 8 years, with membership durations mostly ranging between 7 to 9 years.\n> \n> 10. **Family_Size**: Most customers have a family size of 2 or 3, with single individuals and larger families being less common.\n> \n> 11. **Total_Spend**: The distribution is right-skewed, indicating that while most customers have a lower total spend, there's a tail of customers who spend much more, up to 2500 units of currency.\n> ","metadata":{}},{"cell_type":"markdown","source":"### 2. Categorical Analysis","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming data4 is your DataFrame\nmulti_cat_cols = data4.select_dtypes('category').columns\nprint(multi_cat_cols.values)\n\n# Setting up the figure for multiple subplots with a shared y-axis\nplt.figure(figsize=(12, 4))\n\n# Track the maximum count to set a common y-axis range\nmax_count = 0\nfor col in multi_cat_cols:\n    max_count = max(max_count, data4[col].value_counts().max())\n\n# Plotting bar charts for each categorical column with shared y-axis\nfor i, col in enumerate(multi_cat_cols, 1):\n    plt.subplot(1, 3, i, sharey=ax1 if i > 1 else None)  # Sharing y-axis with the first subplot\n    ax1 = sns.countplot(x=data4[col], order=data4[col].value_counts().index, color='seagreen')\n    plt.title(f'Distribution of {col}')\n    plt.tick_params(axis='x', rotation=45)\n\n    # Set the same y-axis limit for all subplots based on the maximum count found\n    plt.ylim(0, max_count)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:06.277260Z","iopub.execute_input":"2024-05-19T14:52:06.278288Z","iopub.status.idle":"2024-05-19T14:52:06.910247Z","shell.execute_reply.started":"2024-05-19T14:52:06.278251Z","shell.execute_reply":"2024-05-19T14:52:06.909178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_cat_cols = data4.select_dtypes('category').columns\nprint(multi_cat_cols.values)\n\n# Setting up the figure for multiple subplots\nplt.figure(figsize=(12, 4))\n\n# Plotting bar charts for each categorical column\nfor i, col in enumerate(multi_cat_cols, 1):\n    plt.subplot(1, 3, i)\n    sns.countplot(x=data4[col], order = data4[col].value_counts().index, color='seagreen')\n    plt.title(f'Distribution of {col}')\n    plt.tick_params(axis='x', rotation=45)\n    plt.tight_layout()\n    \n    plt.ylim(0, 1200)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:06.911795Z","iopub.execute_input":"2024-05-19T14:52:06.912236Z","iopub.status.idle":"2024-05-19T14:52:07.622559Z","shell.execute_reply.started":"2024-05-19T14:52:06.912199Z","shell.execute_reply":"2024-05-19T14:52:07.621488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> - Higher education levels like \"Graduation\" and \"PhD\" dominate.\n> - Marital status varies widely, but traditional statuses like \"Married\", \"Together\", and \"Single\" are more common than others.\n> - Income distribution across the segments is even, since I divine income by quantile, that mean the income levels will balance distribution.","metadata":{}},{"cell_type":"markdown","source":"### 3. Proportion Analysis\n- Calculate the proportion of each **'Family size'** within each income segment.\n- Calculate the proportion of each **'Education'** within each income segment.","metadata":{}},{"cell_type":"code","source":"# Crosstabulation between Family_Size and Income_Segment\nFamily_Size_income_segment_crosstab = pd.crosstab(data4['Family_Size'], data4['Income_Segment'])\n\n# Visualization using a stacked bar chart\nFamily_Size_income_segment_crosstab.plot(kind='bar', stacked=True, figsize=(6, 4))\nplt.title('Family Size Distribution within Each Income Segment')\nplt.xlabel('Family Size')\nplt.ylabel('Number of Cusomer')\nplt.xticks(rotation=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:07.624178Z","iopub.execute_input":"2024-05-19T14:52:07.624596Z","iopub.status.idle":"2024-05-19T14:52:07.943149Z","shell.execute_reply.started":"2024-05-19T14:52:07.624560Z","shell.execute_reply":"2024-05-19T14:52:07.941933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Overall, the chart indicates that as family size increases, the overall number of customers tends to decrease. Interestingly, larger families appear to be poorer compared to smaller families, particularly in higher income brackets.","metadata":{}},{"cell_type":"code","source":"# Crosstabulation between Education and Income_Segment\neducation_income_segment_crosstab = pd.crosstab(data4['Education'], data4['Income_Segment'])\n\n# Visualization using a stacked bar chart\neducation_income_segment_crosstab.plot(kind='bar', stacked=True, figsize=(6,4))\nplt.title('Education Distribution within Each Income Segment')\nplt.xlabel('Education')\nplt.ylabel('Number of Cusomer')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:07.944759Z","iopub.execute_input":"2024-05-19T14:52:07.945072Z","iopub.status.idle":"2024-05-19T14:52:08.258366Z","shell.execute_reply.started":"2024-05-19T14:52:07.945046Z","shell.execute_reply":"2024-05-19T14:52:08.257214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> - Overall, the chart reveals a clear trend between those with education levels above graduation and those with only basic education. Specifically, basic education is associated solely with the 'Low' income segment. \n> - Conversely, higher education levels, such as a PhD, show no significant difference in income distribution compared to other graduate-level education, such as Master's degrees and Bachelor's degrees.","metadata":{}},{"cell_type":"markdown","source":"### 4. Campaign Responses","metadata":{}},{"cell_type":"code","source":"# Calculating the overall response rates for each campaign\ncampaign_columns = ['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5']\ncampaign_response_rates = data4[campaign_columns].mean() * 100  # Converting to percentages\n\n# Visualization of response rates\nplt.figure(figsize=(6, 4))\nsns.barplot(x=campaign_response_rates.index, y=campaign_response_rates.values)\n\n# Calculate the average and add a horizontal line\naverage_response_rate = campaign_response_rates.mean()\nplt.axhline(average_response_rate, color='red', linestyle='dashed', linewidth=1)\nplt.text(len(campaign_response_rates)+0.7, average_response_rate+0.2, f'Average: {average_response_rate:.2f}%', color='red', ha='right')\n\n\nplt.title('Response Rates for Each Campaign')\nplt.ylabel('Response Rate (%)')\nplt.xticks(rotation=90)\nplt.show()\n\ncampaign_response_rates\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:08.260052Z","iopub.execute_input":"2024-05-19T14:52:08.260510Z","iopub.status.idle":"2024-05-19T14:52:08.701123Z","shell.execute_reply.started":"2024-05-19T14:52:08.260471Z","shell.execute_reply":"2024-05-19T14:52:08.700078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The provided bar chart visualizes the response rates for five different promotional campaigns, with each bar representing the percentage of respondents who accepted the offer in each campaign. \n> 1. Campaigns 3,4  and 5 have the highest response rates, which suggests that the offers or the method of these campaigns were particularly appealing or well-received.\n> 1. Campaign 2's strategy was least effective, given its significantly lower response rate compared to the others.\n> 1. The response rates for Campaigns 1 are moderately successful, falling slightly from highest of the range.","metadata":{}},{"cell_type":"markdown","source":"### 5. Purchasing Behavior\nTo analyze purchasing behavior across different channels, we will focus on variables such as **NumDealsPurchases, NumWebPurchases, NumCatalogPurchases, NumStorePurchases**, and **NumDealsPurchases**. These represent purchases made through the company‚Äôs website, using a catalogue, directly in stores, and purchases made with a discount, respectively. We can approach this analysis by:","metadata":{}},{"cell_type":"code","source":"purchases_data = data4.groupby('Income_Segment')[['NumDealsPurchases','NumWebPurchases',\n                       'NumCatalogPurchases', 'NumStorePurchases',\n                       'NumWebVisitsMonth'\n                      ]].mean()\n\npurchases_data.plot(kind='bar')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:08.702464Z","iopub.execute_input":"2024-05-19T14:52:08.702880Z","iopub.status.idle":"2024-05-19T14:52:09.005523Z","shell.execute_reply.started":"2024-05-19T14:52:08.702846Z","shell.execute_reply":"2024-05-19T14:52:09.004360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The chart you provided shows the purchasing behavior of different income segments across several channels: deals, web, catalog, and store purchases, as well as the number of web visits per month. Let's analyze the trends observed in each income segment:\n> \n> 1. **Deal Purchases**: Correlate with income, indicating that wealthier people do not care much about deal purchases.\n> 1. **Store Purchases**: Correlate with income levels.\n> 1. **Web Purchases**: Show a negative correlation with income.\n> 1. **Catalog Purchases**: Correlate with income levels.\n> 1. **Web Visits**: Show a negative correlation with income.","metadata":{}},{"cell_type":"markdown","source":"### 6. Impact of Website\nNext, let's examine the correlation between web visits and web purchases.","metadata":{}},{"cell_type":"code","source":"purchases_data = data4.groupby('Income_Segment')[['NumWebPurchases','NumWebVisitsMonth']].mean()\n\npurchases_data.plot(kind='bar')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:09.007330Z","iopub.execute_input":"2024-05-19T14:52:09.008105Z","iopub.status.idle":"2024-05-19T14:52:09.245271Z","shell.execute_reply.started":"2024-05-19T14:52:09.008063Z","shell.execute_reply":"2024-05-19T14:52:09.244245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From the chart, we can observe the following key trends regarding the number of web visits per month and the average number of web purchases across different income segments:\n> - There is a clear negative correlation between income level and the number of web visits; as income increases, the frequency of web visits decreases.\n> - Web purchase behavior does not directly correlate with the number of web visits; higher web visits do not necessarily translate to more purchases, especially in lower income segments.\n> - High Income Segment experiences a further decrease in web purchases, despite their lower web visit numbers, which might reflect higher quality or more expensive purchases that occur less frequently.\n> ","metadata":{}},{"cell_type":"markdown","source":"### 7. Impact of 'Family Size'\nFinally, let's investigate the impact of family size on spending habits. We'll create a series of boxplots to observe how family size influences spending on different product categories.","metadata":{}},{"cell_type":"code","source":"spending_columns = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n                    'MntSweetProducts', 'MntGoldProds', 'Total_Spend']\n\n# Impact of Family Size on Spending Habits\nplt.figure(figsize=(15, 10))\n\n# Creating boxplots for each spending category against Family Size\nfor i, col in enumerate(spending_columns, 1):\n    plt.subplot(3, 3, i)\n    sns.boxplot(x=data4['Family_Size'], y=data4[col])\n    plt.title(f'Family Size vs {col}')\n    plt.tight_layout()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:09.246675Z","iopub.execute_input":"2024-05-19T14:52:09.247076Z","iopub.status.idle":"2024-05-19T14:52:11.411825Z","shell.execute_reply.started":"2024-05-19T14:52:09.247040Z","shell.execute_reply":"2024-05-19T14:52:11.410990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">The boxplots provide a visual summary of the spending distribution across different family sizes for various product categories:1. Across all product categories, as family size increases, median spending tends to decrease.\n>1. Single-person families (family size 1) have the greatest variability in spending, which could be due to more disposable income or fewer family obligations.\n>1. Outliers are present in all categories, suggesting that there are exceptions to the general spending patterns within each family size group.\n>1. Smaller families have a wider range of spending, which narrows for larger family sizes, possibly indicating budget constraints or different spending priorities.\n>\n>These insights suggest that **family size does have an influence on spending habits**, with larger families generally spending less on these product categories. This could be due to budget allocation towards other necessities or preferences.","metadata":{}},{"cell_type":"markdown","source":"### 8. Correlation Analysis\nLet's explore the relationships between different variables in the dataset. We'll focus on:\n\n- Income & Spending\n- Webvisit & WebPurchase\n- Family Size & Spending","metadata":{}},{"cell_type":"code","source":"spending_columns = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n                    'MntSweetProducts', 'MntGoldProds', 'Total_Spend']\n\n# Function to format the tick labels\ndef format_tick(value, pos):\n    return f'{int(value/1000)}k' if value >= 1000 else str(int(value))\n\n# Setting up the figure for multiple subplots\nplt.figure(figsize=(15, 10))\n\n# Creating scatter plots with red regression lines for each spending category against Income\nfor i, col in enumerate(spending_columns, 1):\n    plt.subplot(3, 3, i)\n    sns.regplot(x=data4['Income'], y=data4[col], marker='x', scatter_kws={'alpha':0.3}, line_kws={\"color\": \"red\", 'alpha':0.3})\n    plt.title(f'Income vs {col}')\n    \n    # Get current axis\n    ax = plt.gca()\n    \n    # Set x-tick labels with the custom formatter\n    ax.set_xticklabels([format_tick(x, pos) for x, pos in zip(ax.get_xticks(), range(len(ax.get_xticks())))])\n\n    plt.tight_layout()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:11.413031Z","iopub.execute_input":"2024-05-19T14:52:11.413534Z","iopub.status.idle":"2024-05-19T14:52:14.857161Z","shell.execute_reply.started":"2024-05-19T14:52:11.413505Z","shell.execute_reply":"2024-05-19T14:52:14.856059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The scatter plots reveal interesting patterns in the relationship between income and spending on various products:\n>\n> 1. **Income vs MntWines**: There seems to be the strongest positive correlation, suggesting that higher income customers tend to spend more on wines.\n> 1. **Income vs MntFruits, MntMeatProducts, MntFishProducts, MntSweetProducts**: These categories also show a similar trend, with higher spending observed at higher income levels, although the correlation appears weaker compared to wine.\n> 1. **Income vs MntGoldProds**: The pattern is less clear, but there is still an indication that higher income might lead to higher spending on gold products.","metadata":{}},{"cell_type":"markdown","source":"### 9. Analyzing Variables Across Segments\nWe'll then examine key variables across these income segments to observe how spending patterns\nFor Numerical Variables: We'll use boxplots to compare the distribution of key numerical variables across different income segments. This will help us understand how variables like 'MntWines', 'MntMeatProducts', and others vary with income.\n","metadata":{}},{"cell_type":"code","source":"# Visualization for Numerical Variables across Income Segments\nnumerical_variables_for_visualization = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', \n                                         'MntSweetProducts','MntGoldProds', 'Total_Spend']\n\n# Setting up the figure for multiple subplots\nplt.figure(figsize=(15, 12))\n\n# Creating boxplots for each numerical variable\nfor i, col in enumerate(numerical_variables_for_visualization, 1):\n    plt.subplot(3, 3, i)\n    sns.boxplot(x=data4['Income_Segment'], y=data4[col])\n    plt.title(f'{col} by Income Segment')\n    plt.tight_layout()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:14.858637Z","iopub.execute_input":"2024-05-19T14:52:14.859346Z","iopub.status.idle":"2024-05-19T14:52:17.202715Z","shell.execute_reply.started":"2024-05-19T14:52:14.859306Z","shell.execute_reply":"2024-05-19T14:52:17.201384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The boxplots provide a visual representation of how key numerical variables vary across different income segments:\n> \n> 1. The observation ranking by Income more family's imcome is more family spend across products category.\n> 1. Wine is the most obious product that we can see the different level of spendign across family weath.\n> 1. Gold was the only product that 'Mid-High' and 'Hign' family spend similarly. This can infer..","metadata":{}},{"cell_type":"markdown","source":"# Remove Unused columns After Analysed <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>\n\nWhen preparing data for a customer segmentation analysis using a clustering model, the choice of which columns to drop depends on the relevance of the data to the analysis objectives.","metadata":{}},{"cell_type":"code","source":"data_new = data4.copy()\n\n# Step 1: Remove unused columns\ndrop_cols = ['Year_Birth', 'Marital_Status', 'Dt_Customer', 'Kidhome', 'Teenhome', 'Adulthome'\n             , 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5']\ndata_processed = data_new.drop(columns=drop_cols)\n\ndisplay(data_new.head())\nprint(data_new.shape)\nprint(\"\\nAfter remove columns: \")\ndisplay(data_processed.head())\nprint(data_processed.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:17.204124Z","iopub.execute_input":"2024-05-19T14:52:17.204565Z","iopub.status.idle":"2024-05-19T14:52:17.249703Z","shell.execute_reply.started":"2024-05-19T14:52:17.204519Z","shell.execute_reply":"2024-05-19T14:52:17.248606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Proprocessing <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>\n---\n\n### How to deal with many columns dataset\n\nDealing with high-dimensional data can be complex due to computational demands, increased risk of overfitting, and difficulty in visualizing or interpreting the data. Principal Component Analysis (PCA) is a common method for addressing these challenges.\n\n### What is PCA?\nPCA is a linear transformation technique used to reduce the dimensionality of a dataset while preserving the maximum variance. It does this by finding new axes, known as principal components, which represent the directions of greatest variance in the data.\n\n### Steps to Use PCA with High-Dimensional Data\n\n1. **Standardize the Data**: <br>\nHigh-dimensional data often contain features with different scales. Standardize (or normalize) the data to ensure each feature has a mean of zero and a standard deviation of one. This step is crucial for PCA to work effectively.\n\n2. **Fit PCA**: <br>\nApply PCA to the standardized data to obtain the principal components. You can specify the number of components to retain based on the cumulative explained variance or a specific number of components.\n\n3. **Choose the Number of Components**: <br>\nDetermine the optimal number of principal components to retain. You can plot the explained variance ratio to find the point where adding more components yields diminishing returns.\nHow to do PCA\n\n4. **Use PCA for Dimensionality Reduction**: <br>\nOnce you've determined the optimal number of components, use the principal components to transform the original dataset, effectively reducing its dimensionality. This new dataset can be used for machine learning or data analysis tasks.\n\n5. **Visualize the Reduced Data**: <br>\nWith fewer dimensions, it's easier to visualize the data. You can plot the first two or three principal components to see how the data points are distributed.","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## Step 1: Standardize and Encode the Data","metadata":{}},{"cell_type":"code","source":"# Step 1: Standardize the Data:\n\nnumerical_cols = data_processed.select_dtypes(include=['int32', 'int64', 'float64']).columns\ncategorical_cols = data_processed.select_dtypes(include=['object', 'category', 'boolean']).columns\n\nprint(\"Numeric: {}\".format(numerical_cols.values))\nprint(\"\\n\")\nprint(\"Category: {}\".format(categorical_cols.values))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:17.251184Z","iopub.execute_input":"2024-05-19T14:52:17.251700Z","iopub.status.idle":"2024-05-19T14:52:17.261011Z","shell.execute_reply.started":"2024-05-19T14:52:17.251664Z","shell.execute_reply":"2024-05-19T14:52:17.259851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 3: Create a Column Transformer for standardizing and encoding\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_cols),\n        ('cat', OneHotEncoder(), categorical_cols)\n    ])\n\n# Apply the transformations to the data\npreprocessed_data = preprocessor.fit_transform(data_processed)\n\n# Checking the shape of the transformed data\npreprocessed_data_shape = preprocessed_data.shape\n\nprint(\"Original data has {} columns\".format(data_new.shape[1]))\nprint(\"Prepreocessed data has {} columns\".format(preprocessed_data_shape[1]))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:17.262293Z","iopub.execute_input":"2024-05-19T14:52:17.262638Z","iopub.status.idle":"2024-05-19T14:52:17.285984Z","shell.execute_reply.started":"2024-05-19T14:52:17.262611Z","shell.execute_reply":"2024-05-19T14:52:17.285245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2 Fit PCA","metadata":{}},{"cell_type":"code","source":"# Step 2 Fit PCA:\n\n# The number of components is not specified, so PCA will retain all components but ordered by explained variance\npca = PCA()\npca_data = pca.fit_transform(preprocessed_data)\n\n# Getting the explained variance ratio to determine how many components to keep\nexplained_variance_ratio = pca.explained_variance_ratio_\n\n# Displaying the cumulative explained variance to decide on the number of components\ncumulative_explained_variance = explained_variance_ratio.cumsum()\n\ncumulative_explained_variance\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:17.287348Z","iopub.execute_input":"2024-05-19T14:52:17.287661Z","iopub.status.idle":"2024-05-19T14:52:17.311954Z","shell.execute_reply.started":"2024-05-19T14:52:17.287635Z","shell.execute_reply":"2024-05-19T14:52:17.310535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Choose the Number of Components","metadata":{}},{"cell_type":"code","source":"# Creating subplot [1, 2] for the provided plots\nplt.figure(figsize=(12, 6))\n\n# First plot: Bar chart for explained variance ratio\nplt.subplot(1, 2, 1)\nplt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio)\nplt.xlabel('Number of Components')\nplt.ylabel('Explained Variance Ratio')\nplt.title('Explained Variance Ratio by PCA Components')\nplt.grid(True)\n\n# Second plot: Line plot for cumulative explained variance\nplt.subplot(1, 2, 2)\nplt.plot(cumulative_explained_variance, marker='o')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.title('Cumulative Explained Variance by PCA Components')\nplt.grid(True)\n\n# Show the combined plot\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:17.314018Z","iopub.execute_input":"2024-05-19T14:52:17.314453Z","iopub.status.idle":"2024-05-19T14:52:18.004735Z","shell.execute_reply.started":"2024-05-19T14:52:17.314405Z","shell.execute_reply":"2024-05-19T14:52:18.003498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4: Use PCA for Dimensionality Reduction:","metadata":{}},{"cell_type":"code","source":"# Applying PCA with 15 components\npca_15 = PCA(n_components=15)\npca_15.fit(preprocessed_data)\n\n\n# Shape of Preprocessed Data\nprint(\"The shape of the preprocessed data before applying PCA:\")\nprint(f\"Number of observations: {preprocessed_data.shape[0]}\")\nprint(f\"Number of features: {preprocessed_data.shape[1]}\")\n\n\n# Principal Components\nprint(\"\\n\\n====After applying PCA ==== \")\nprint(f\"Shape of PCA components: {pca_15.components_.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:18.006149Z","iopub.execute_input":"2024-05-19T14:52:18.006702Z","iopub.status.idle":"2024-05-19T14:52:18.083719Z","shell.execute_reply.started":"2024-05-19T14:52:18.006672Z","shell.execute_reply":"2024-05-19T14:52:18.082430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n# Visualizing the importance of each original variable in the first few principal components\n# We will use a heatmap for this purpose\n\n# Reconstructing the feature names after one-hot encoding\nfeature_names = numerical_cols.tolist() + preprocessor.named_transformers_['cat'].get_feature_names_out().tolist()\n\n# Correctly displaying the PCA loadings with the transformed feature names\npca_loadings_corrected = pd.DataFrame(pca_15.components_, columns=feature_names)\n\nplt.figure(figsize=(12, 8))\nsns.heatmap(pca_loadings_corrected.iloc[:5, :].transpose(), \n            cmap='YlGnBu', \n            annot=True, \n            fmt=\".2f\", \n            cbar_kws={'label': 'Loading Value'},\n            xticklabels=[f'PC{i}' for i in range(1,6)])\nplt.title('PCA Loadings - Importance of Each Original Variable in the First 5 Components')\nplt.xlabel('Principal Component')\nplt.ylabel('Original Variable')\nplt.yticks(rotation=0)  # To keep the variable names readable\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:18.085302Z","iopub.execute_input":"2024-05-19T14:52:18.086737Z","iopub.status.idle":"2024-05-19T14:52:19.022339Z","shell.execute_reply.started":"2024-05-19T14:52:18.086696Z","shell.execute_reply":"2024-05-19T14:52:19.021265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5: Visualize the Reduced Data:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Transforming the preprocessed data with PCA to reduce its dimensions\nreduced_data = pca_15.transform(preprocessed_data)\n\n# Checking the shape of the reduced data\nprint(\"Shape of the reduced data:\", reduced_data.shape)\n\n# Converting the reduced data to a DataFrame for better readability\nreduced_data_df = pd.DataFrame(reduced_data, columns=[f'PC{i+1}' for i in range(reduced_data.shape[1])])\n\n# Displaying the first few rows of the reduced data\nprint(\"First few rows of the reduced PCA data:\")\ndisplay(reduced_data_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:19.023743Z","iopub.execute_input":"2024-05-19T14:52:19.024066Z","iopub.status.idle":"2024-05-19T14:52:19.055038Z","shell.execute_reply.started":"2024-05-19T14:52:19.024040Z","shell.execute_reply":"2024-05-19T14:52:19.053881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clustering with K-Means <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>\n\n### How can we cluster data?\nClustering is a technique used in data mining and machine learning to group similar data points together. There are various algorithms for clustering, but one of the most popular methods is K-means clustering. \n\n### Why can K-means cluster data?\nK-means is one of the most popular clustering algorithms because of its simplicity and efficiency. It works based on the following principles:\n\n### How can we select the number of clusters in K-means?\nSelecting the optimal number of clusters, often denoted by \"K\", is a crucial step in K-means clustering. Several methods can be used for this purpose, with one of the most commonly employed being the Elbow method. In the Elbow method, the within-cluster sum of squares (WCSS) is plotted against the number of clusters. The \"elbow point\" represents the optimal number of clusters, where adding more clusters does not significantly reduce WCSS.\n\n### Selecting Kmeans's Number of Clusters\nIdentify Elbow Point: Examine the plot. The point where the rate of decrease of WCSS slows down (forming an \"elbow\" shape) is often a good indication of the appropriate number of clusters. This is because adding more clusters beyond this point may not significantly reduce the WCSS.","metadata":{}},{"cell_type":"code","source":"# Calculate WCSS for different number of clusters\nwcss = []  # Within-Cluster-Sum-of-Squares\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n    kmeans.fit(reduced_data)\n    wcss.append(kmeans.inertia_)\n\n# Plotting the results onto a line graph to observe 'The elbow'\nplt.figure(figsize=(10, 6))\nlines = plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n\n# Annotate the 3rd marker\nthird_marker = lines[0].get_xydata()[2]  # Get the x,y coordinates of the 3rd point\nplt.scatter(*third_marker, s=100, color='red')  # Highlight the 3rd marker\nplt.annotate('Elbow Point', (third_marker[0], third_marker[1]), textcoords=\"offset points\", xytext=(-10,10), ha='center', color='red')\n\nplt.title('Elbow Method For Optimal Number of Clusters')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')  # Within cluster sum of squares\nplt.grid(True)\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:19.057139Z","iopub.execute_input":"2024-05-19T14:52:19.057622Z","iopub.status.idle":"2024-05-19T14:52:32.439479Z","shell.execute_reply.started":"2024-05-19T14:52:19.057574Z","shell.execute_reply":"2024-05-19T14:52:32.437540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#temp\n\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n# Assuming 'reduced_data' contains your data after dimensionality reduction\n\n# Number of clusters to try\ncluster_counts = [2, 3, 4, 5, 6, 7]\n\nn_rows = 2\nn_cols = 3\n\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 10))\n\nfor i, k in enumerate(cluster_counts):\n    row = i // n_cols\n    col = i % n_cols\n\n    # Apply K-means clustering\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    clusters = kmeans.fit_predict(reduced_data)\n\n    # Scatter plot using the first two principal components\n    axes[row, col].scatter(reduced_data[:, 0], reduced_data[:, 1], c=clusters, cmap='viridis', marker='o', alpha=0.3)\n    axes[row, col].set_title(f'K-Means Clustering with {k} Clusters', size=16)\n    axes[row, col].set_xlabel('Principal Component 1')\n    axes[row, col].set_ylabel('Principal Component 2')\n    axes[row, col].grid(True)\n\nplt.tight_layout()\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:32.440807Z","iopub.execute_input":"2024-05-19T14:52:32.441147Z","iopub.status.idle":"2024-05-19T14:52:42.015126Z","shell.execute_reply.started":"2024-05-19T14:52:32.441120Z","shell.execute_reply":"2024-05-19T14:52:42.012265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The analysis of the K-Means clustering plots for ùëò k values ranging from 2 to 7 suggests that **k=3** is the most suitable choice for clustering this data, the clusters are distinct, well-separated, and each captures a dense group of data points, providing a clear and meaningful partition of the dataset. Increasing the number of clusters beyond three leads to overlaps and potentially over-segmentation","metadata":{}},{"cell_type":"markdown","source":"## Apply the chosen number of clusters","metadata":{}},{"cell_type":"code","source":"# Assigninge color palette\npalette = 'viridis'\n\n# Assigning cluster labels\nkmeans_3_clusters = KMeans(n_clusters=3, random_state=42)\ncluster_labels = kmeans_3_clusters.fit_predict(reduced_data)\ndata_new['Cluster'] = cluster_labels\n\nplt.figure(figsize=(10, 6))\n\n# Using seaborn's scatter plot with a KDE overlay for each cluster\nsns.scatterplot(data=data_new, x='Income', y='Total_Spend', hue='Cluster', palette=palette, alpha=1)\n#     sns.kdeplot(data=data_new, x='Income', y=col, hue='Cluster', palette=palette, alpha=.9, linewidths=1)\nplt.title(f'Income vs Total spend with Cluster Density')\nplt.xlabel('Income')\nplt.ylabel('Total spend')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:52:42.016841Z","iopub.execute_input":"2024-05-19T14:52:42.017194Z","iopub.status.idle":"2024-05-19T14:52:43.792537Z","shell.execute_reply.started":"2024-05-19T14:52:42.017160Z","shell.execute_reply":"2024-05-19T14:52:43.791366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>","metadata":{}},{"cell_type":"markdown","source":"## Key observations from the clustering results:\n\n1. **Cluster Characteristics**:\n   - **<p style=\"color: purple;\">Cluster 0 (Purple)</p>**: Represents customers with a wide range of incomes but generally lower total spending. This is the largest cluster and suggests a group of customers who are conservative spenders across different income levels.\n   - **<p style=\"color: teal;\">Cluster 1 (Teal)</p>**: Encompasses customers with moderate incomes and moderate to high total spending. This cluster is tightly packed, indicating a strong correlation between income and spending for this group.\n   - **<p style=\"color: gold;\">Cluster 2 (Yellow)</p>**: Contains customers with high incomes and high total spending. It appears to be smaller and more spread out than the other two clusters, suggesting these are premium customers who vary more in their spending despite high incomes.\n\n\n<br>\n\n2. **Income vs. Spend Correlation**:\n   - There is a positive correlation between income and total spend, which is most apparent in clusters 1 and 2. As income increases, total spend also tends to increase.","metadata":{}},{"cell_type":"markdown","source":"# SWOT Analysis and Next Steps <span style=' border:1; color:#95E885; text-align:left; font-size:42px;  padding:6px;'>|</span>\n\n\n#### <p style=\"color: purple;\">Cluster 0 (Purple): Conservative Spenders</p>\n| **Category** | **Description** |\n|:--------------|:-----------------|\n| **Strengths** | Large customer base, stable revenue, less impacted by economic changes. |\n| **Weaknesses** | Low revenue per customer, limited growth. |\n| **Opportunities** | Upsell services, create loyalty programs to boost spending. |\n| **Threats** | Price sensitive, risk of losing to cheaper options. |\n| **Next Steps** | Offer affordable products, improve rewards in loyalty programs. |\n\n#### <p style=\"color: teal;\">Cluster 1 (Teal): Middle Income, Moderate to High Spenders</p>\n| **Category** | **Description** |\n|:--------------|:-----------------|\n| **Strengths** | Regular spending, responds well to value-focused marketing. |\n| **Weaknesses** | Limited extra money for luxuries, faces lots of competition. |\n| **Opportunities** | Introduce varied product levels, use targeted marketing. |\n| **Threats** | Vulnerable to economic downturns, could lose customers to different brands. |\n| **Next Steps** | Use data to customize products and ads, offer bundled products. |\n\n#### <p style=\"color: gold;\">Cluster 2 (Yellow): High Income, High Spenders</p>\n| **Category** | **Description** |\n|:--------------|:-----------------|\n| **Strengths** | More profitable, likes high-end products. |\n| **Weaknesses** | Fewer customers, expects high quality. |\n| **Opportunities** | Sell unique, high-quality items, provide personalized service. |\n| **Threats** | Spending may drop during economic hardship, faces strong competition. |\n| **Next Steps** | Focus on high-end products and services, enhance personalized shopping experiences. |\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}